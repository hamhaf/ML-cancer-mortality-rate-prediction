{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d67FXFqGEIHQ"
   },
   "source": [
    "# **Predict Cancer Mortality Rates in US Counties**\n",
    "\n",
    "The provided dataset comprises data collected from multiple counties in the US. The regression task for this assessment is to predict cancer mortality rates in \"unseen\" US counties, given some training data. The training data ('Training_data.csv') comprises various features/predictors related to socio-economic characteristics, amongst other types of information for specific counties in the country. The corresponding target variables for the training set are provided in a separate CSV file ('Training_data_targets.csv'). Use the notebooks provided for lab sessions throughout this module to provide solutions to the exercises listed below. Throughout all exercises, text describing your code and answering any questions included in the exercise descriptions should be provided as part of your submitted solution. (Total Marks for this Assessment is 40)\n",
    "\n",
    "Note - We also provide an example test data set ('Test_data_example.csv' and 'Test_data_example_targets.csv'). This is just an example of the final test set (which will not be provided to you) that will be used to evaluate your solutions when your submitted solutions are being marked. Part of this assessment requires you to write an inference script that evaluates the regression models you have trained on the final test data set such that we are able to run the inference script ourselves on the test data (you can use the example test data to verify that it works prior to submission).\n",
    "\n",
    "The list of predictors/features available in this data set are described below:\n",
    "\n",
    "**Data Dictionary**\n",
    "\n",
    "avgAnnCount: Mean number of reported cases of cancer diagnosed annually\n",
    "\n",
    "avgDeathsPerYear: Mean number of reported mortalities due to cancer\n",
    "\n",
    "incidenceRate: Mean per capita (100,000) cancer diagoses\n",
    "\n",
    "medianIncome: Median income per county \n",
    "\n",
    "popEst2015: Population of county \n",
    "\n",
    "povertyPercent: Percent of populace in poverty \n",
    "\n",
    "MedianAge: Median age of county residents \n",
    "\n",
    "MedianAgeMale: Median age of male county residents \n",
    "\n",
    "MedianAgeFemale: Median age of female county residents \n",
    "\n",
    "AvgHouseholdSize: Mean household size of county \n",
    "\n",
    "PercentMarried: Percent of county residents who are married \n",
    "\n",
    "PctNoHS18_24: Percent of county residents ages 18-24 highest education attained: less than high school \n",
    "\n",
    "PctHS18_24: Percent of county residents ages 18-24 highest education attained: high school diploma \n",
    "\n",
    "PctSomeCol18_24: Percent of county residents ages 18-24 highest education attained: some college \n",
    "\n",
    "PctBachDeg18_24: Percent of county residents ages 18-24 highest education attained: bachelor's degree \n",
    "\n",
    "PctHS25_Over: Percent of county residents ages 25 and over highest education attained: high school diploma \n",
    "\n",
    "PctBachDeg25_Over: Percent of county residents ages 25 and over highest education attained: bachelor's degree \n",
    "\n",
    "PctEmployed16_Over: Percent of county residents ages 16 and over employed \n",
    "\n",
    "PctUnemployed16_Over: Percent of county residents ages 16 and over unemployed \n",
    "\n",
    "PctPrivateCoverage: Percent of county residents with private health coverage \n",
    "\n",
    "PctPrivateCoverageAlone: Percent of county residents with private health coverage alone (no public assistance) \n",
    "\n",
    "PctEmpPrivCoverage: Percent of county residents with employee-provided private health coverage \n",
    "\n",
    "PctPublicCoverage: Percent of county residents with government-provided health coverage \n",
    "\n",
    "PctPubliceCoverageAlone: Percent of county residents with government-provided health coverage alone \n",
    "\n",
    "PctWhite: Percent of county residents who identify as White \n",
    "\n",
    "PctBlack: Percent of county residents who identify as Black \n",
    "\n",
    "PctAsian: Percent of county residents who identify as Asian \n",
    "\n",
    "PctOtherRace: Percent of county residents who identify in a category which is not White, Black, or Asian \n",
    "\n",
    "PctMarriedHouseholds: Percent of married households \n",
    "\n",
    "BirthRate: Number of live births relative to number of women in county "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "kB3aG5f-D4Q4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Define paths to the training data and targets files\n",
    "training_data_path = 'Training_data.csv'\n",
    "training_targets_path = 'Training_data_targets.csv'\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHfmuohnJcc_"
   },
   "source": [
    "# **Exercise 1**\n",
    "\n",
    "Read in the training data and targets files. The training data comprises features/predictors while the targets file comprises the targets (i.e. cancer mortality rates in US counties) you need to train models to predict. Plot histograms of all features to visualise their distributions and identify outliers. Do you notice any unusual values for any of the features? If so comment on these in the text accompanying your code. Compute correlations of all features with the target variable (across the data set) and sort them according the strength of correlations. Which are the top five features with strongest correlations to the targets? Plot these correlations using the scatter matrix plotting function available in pandas and comment on at least two sets of features that show visible correlations to each other. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "OlTEKBhiM0U5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in training and target files as csv\n",
    "training = pd.read_csv(training_data_path)\n",
    "targets = pd.read_csv(training_targets_path)\n",
    "\n",
    "# histograms for all features \n",
    "training.hist(bins=30, figsize=(20,15))\n",
    "\n",
    "# identify outliers\n",
    "# avgHouseholdSize has a small value which outlies from the rest of the data\n",
    "# by examining the training dataset directly, I also noticed some very \n",
    "# implausible values for the median age variable. There were 26 records where \n",
    "# the median age was more than 300 - this obviously could not be true\n",
    "# small bars, huge whitespace (range extends far), large scale for x axis - outliers exist inthe distribution, but not necessarily implausible e.g. predominantly black areas\n",
    "\n",
    "combined = pd.merge(training, targets, left_index=True, right_index=True)\n",
    "corr_matrix=combined.corr()\n",
    "sortedCorrs = corr_matrix.reindex(corr_matrix.TARGET_deathRate.abs().sort_values(ascending=False).index)[\"TARGET_deathRate\"]\n",
    "print(sortedCorrs)\n",
    "\n",
    "attributes=[\"TARGET_deathRate\",\"PctBachDeg25_Over\",\"incidenceRate\",\"PctPublicCoverageAlone\",\"medIncome\",\"povertyPercent\"]\n",
    "\n",
    "scatter_matrix(combined[attributes],figsize=(12,8))\n",
    "\n",
    "plt.savefig('scatter_matrix.png')\n",
    "\n",
    "# PctPublicCoverageAlone - PovertyPercent\n",
    "# When plotting PovertyPercent against PctPublicCoverageAlone, there is a clear and strong positive correlation between the features.\n",
    "# As the value for PovertyPercent increases i.e., the percentage of the populace in poverty increase, the value for PctPublicCoverageAlone also increases i.e., the percentage of the \n",
    "# population with government funded healthcare also increases. This makes sense intuitively, as you'd expect there to be more\n",
    "# people who require government funding for healthcare in areas of higher poverty.\n",
    "\n",
    "# PctBachDeg25_Over - medIncome\n",
    "# When plotting PctBachDeg25_Over (the percentage of the population in a county aged 25< with a degree) against the medianIncome \n",
    "# in the respective county, there is a clear positive correlation between the two features. This also makes sense intuitively, as you'd \n",
    "# expect the average salary to increase given that someone has a degree and hence, where there is a higher percentage of people\n",
    "# with degrees, you find a higher median income value for that county. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OUTLIERS:***\n",
    "- avgHouseholdSize has a small bar towards 0 which outlies from the rest of the data\n",
    "  - when looking directly at the dataset, there exists 48 records with extremely low values for this feature, which outlie from the rest of the values for the avgHouseholdSize feature\n",
    "  - it doesn't make sense for mean household size to be less than 1 person\n",
    "\n",
    "- After noticing the large scale for median age and examining the training dataset directly, I also noticed some very implausible values for the median age variable. \n",
    "  - There were 26 records where the median age was more than 300 - this obviously could not be true\n",
    "  - an age more than 150 is not realistic, considering the oldest person alive is 118...\n",
    "  - and lives in France\n",
    "\n",
    "- A few other features also seemed to have outliers. I noticed a lot of features that had a majority of the data distributed in one area of the histogram with a large amount of whitespace on either the right, left or both sides with very small bars at extreme values of the x axis. I considered these features as having outliers, however I wouldn't say the values were necessarily implausible since, for example, an extremely high value for PctBlack could exist in counties where the majority of the population are black.\n",
    "  - Features related to this would be: avgAnnCount, avgDeathsPerYear, incidenceRate, medIncome, popEst2015, studyPerCap, PctWhite, PctBlack, PctAsian, PctOtherRace\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CORRELATIONS:***\n",
    "- order of correlations (using absolute value) - the rest of the features are printed above\n",
    "  - \"PctBachDeg25_Over\"\n",
    "  - \"incidenceRate\"\n",
    "  - \"PctPublicCoverageAlone\"\n",
    "  - \"medIncome\"\n",
    "  - \"povertyPercent\"\n",
    "\n",
    "- related features:\n",
    "  - PctPublicCoverageAlone - PovertyPercent\n",
    "    - When plotting PovertyPercent against PctPublicCoverageAlone, there is a clear and strong positive correlation between the features.\n",
    "As the value for PovertyPercent increases i.e., the percentage of the populace in poverty increase, the value for PctPublicCoverageAlone also increases i.e., the percentage of the \n",
    "population with government funded healthcare also increases. This makes sense intuitively, as you'd expect there to be more\n",
    "people who require government funding for healthcare in areas of higher poverty.\n",
    "\n",
    "  - PctBachDeg25_Over - medIncome\n",
    "    - When plotting PctBachDeg25_Over (the percentage of the population in a county aged 25< with a degree) against the medianIncome \n",
    "in the respective county, there is a clear positive correlation between the two features. This also makes sense intuitively, as you'd \n",
    "expect the average salary to increase given that someone has a degree and hence, where there is a higher percentage of people\n",
    "with degrees, you find a higher median income value for that county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for my own interest, to see how other features correlate with each other\n",
    "# attributes=[\"TARGET_deathRate\",\"incidenceRate\",\"PctPublicCoverageAlone\",\"medIncome\",\"povertyPercent\", \"avgAnnCount\", \"avgDeathsPerYear\", \"popEst2015\"]\n",
    "\n",
    "# scatter_matrix(combined[attributes],figsize=(12,8), alpha=0.3)\n",
    "# plt.savefig('scatter_matrix_full.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc ranges\n",
    "# columns = combined.columns.values.tolist()\n",
    "\n",
    "# for column in columns:\n",
    "#   range = combined[column].max() - combined[column].min()\n",
    "#   print(f\"column: {column}, range: {range}\")\n",
    "\n",
    "# median age range shows there are outliers in median age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show maximums\n",
    "# columns = combined.columns.values.tolist()\n",
    "\n",
    "# for column in columns:\n",
    "#   max = combined[column].max()\n",
    "#   print(f\"column: {column}, max: {max}\")\n",
    "\n",
    "# median age definitely has outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wSA10GzM_Xu"
   },
   "source": [
    "# **Exercise 2**\n",
    "\n",
    "Create an ML pipeline using scikit-learn (as demonstrated in the lab notebooks) to pre-process the training data. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the rows with unrealistic median age values and avgHouseholdSize values\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "remove_columns = ['MedianAge', 'MedianAgeFemale', 'studyPerCap', 'AvgHouseholdSize', \n",
    "                    'PctPrivateCoverageAlone', 'PctNoHS18_24', 'PctSomeCol18_24']\n",
    "\n",
    "class RemoveImplausibleValues(BaseEstimator):\n",
    "    \n",
    "    def fit(self,X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # X = X[~((X['MedianAge'] > 150) | (X['AvgHouseholdSize'] <1))]\n",
    "        for column in remove_columns:\n",
    "            X.drop(column, axis=1, inplace=True)\n",
    "        return X\n",
    "\n",
    "\n",
    "# print(len(combined))\n",
    "# combined = combined[~((combined['MedianAge'] > 300) | (combined['AvgHouseholdSize'] <1))]\n",
    "# print(len(combined))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***REMOVING IMPLAUSIBLE VALUES FROM THE DATASET:*** I decided to remove the outliers mentioned earlier by removing any records with median age over 150 or avg household size less than 1. These rules make intuitive sense, so should fit well even with an unseen test set, since it is currently impossible to find a human over the age of 150 and does not make sense for an average household size to be less than 1 person (especially when the rest of the dataset are distributed between having 1-2 people on average, per household)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2438, 32)\n",
      "(2438, 25)\n"
     ]
    }
   ],
   "source": [
    "# before splitting the data, remove records with implausible values\n",
    "# create scikit learn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "initial_pipeline = Pipeline([\n",
    "    ('RemoveImplausibleValues',RemoveImplausibleValues())\n",
    "])\n",
    "\n",
    "print(combined.shape)\n",
    "combined_ppln = initial_pipeline.fit_transform(combined).reset_index(drop=True)\n",
    "# combined_ppln[\"TARGET_deathRate\"].head()\n",
    "print((combined_ppln.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_deathRate          1.000000\n",
      "PctBachDeg25_Over        -0.491411\n",
      "incidenceRate             0.443983\n",
      "PctPublicCoverageAlone    0.439734\n",
      "medIncome                -0.416607\n",
      "povertyPercent            0.413260\n",
      "PctHS25_Over              0.409915\n",
      "PctEmployed16_Over       -0.400317\n",
      "PctPublicCoverage         0.391899\n",
      "PctPrivateCoverage       -0.382786\n",
      "PctUnemployed16_Over      0.362612\n",
      "PctMarriedHouseholds     -0.290645\n",
      "PctBachDeg18_24          -0.284566\n",
      "PctHS18_24                0.266285\n",
      "PercentMarried           -0.266153\n",
      "PctEmpPrivCoverage       -0.259006\n",
      "PctBlack                  0.236380\n",
      "PctOtherRace             -0.182602\n",
      "PctAsian                 -0.181948\n",
      "PctWhite                 -0.174521\n",
      "avgAnnCount              -0.150019\n",
      "popEst2015               -0.130122\n",
      "avgDeathsPerYear         -0.094048\n",
      "BirthRate                -0.088543\n",
      "MedianAgeMale            -0.027263\n",
      "Name: TARGET_deathRate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# recalculate correlations\n",
    "corr_matrix=combined_ppln.corr()\n",
    "sortedCorrs = corr_matrix.reindex(corr_matrix.TARGET_deathRate.abs().sort_values(ascending=False).index)[\"TARGET_deathRate\"]\n",
    "print(sortedCorrs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any changes from before removing weird values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combined_ppln.columns[combined_ppln.isnull().any()].tolist())\n",
    "# PctSomeCol18_24 = combined_ppln['PctSomeCol18_24'].isnull().sum()\n",
    "# PctEmployed16_Over = combined_ppln['PctEmployed16_Over'].isnull().sum()\n",
    "# PctPrivateCoverageAlone = combined_ppln['PctPrivateCoverageAlone'].isnull().sum()\n",
    "\n",
    "# print(\"PctSomeCol18_24\", PctSomeCol18_24, 100*(PctSomeCol18_24/len(combined_ppln)))\n",
    "# print('PctEmployed16_Over', PctEmployed16_Over, 100*(PctEmployed16_Over/len(combined_ppln)))\n",
    "# print('PctPrivateCoverageAlone', PctPrivateCoverageAlone, 100*(PctPrivateCoverageAlone/len(combined_ppln)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ['PctSomeCol18_24', 'PctEmployed16_Over', 'PctPrivateCoverageAlone'] have missing values\n",
    "- PctSomCol18_24 has a huge amount missing (75%)\n",
    "  - -0.186140 correlation \n",
    "  - 18th most correlated - in the bottom 50% of features in terms of correlation\n",
    "  - I ended up deciding to remove this column earlier on anyway\n",
    "- PctEmployed16_Over has only a few (5%)\n",
    "  - -0.400317 correlation \n",
    "  - 7th most correlated  - this is high!\n",
    "- PctPrivateCoverageAlone has a lot missing (20%)\n",
    "  - -0.355050 correlation \n",
    "  - 11th most correlated - also quite high\n",
    "  - I ended up deciding to remove this column earlier on anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and test set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "\n",
    "def stratified_split(df, feature):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,random_state=42)\n",
    "    \n",
    "    # returns 2 sets of indexes for test and train\n",
    "    # hence, .loc is used on the dataset df to retrieve the corresponding records\n",
    "    for train_index, test_index in split.split(df,df[feature]):\n",
    "        strat_train_set = df.loc[train_index]\n",
    "        strat_test_set = df.loc[test_index]\n",
    "    \n",
    "    # for set_ in (strat_train_set, strat_test_set):\n",
    "    #     set_.drop((feature),axis=1,inplace=True)\n",
    "        \n",
    "   \n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "\n",
    "def shuffle_split(df, target):\n",
    "    split = ShuffleSplit(n_splits=1, test_size=0.2,random_state=42)\n",
    "    \n",
    "    # returns 2 sets of indexes for test and train\n",
    "    # hence, .loc is used on the dataset df to retrieve the corresponding records\n",
    "    for train_index, test_index in split.split(df,df[target]):\n",
    "        train_set = df.loc[train_index]\n",
    "        test_set = df.loc[test_index]\n",
    "    \n",
    "#     for set_ in (strat_train_set, strat_test_set):\n",
    "#         set_.drop((target),axis=1,inplace=True)\n",
    "        \n",
    "   \n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "train_set, test_set = shuffle_split(combined_ppln, 'TARGET_deathRate')\n",
    "\n",
    "training_set=train_set.drop(\"TARGET_deathRate\",axis=1)\n",
    "training_labels=train_set[\"TARGET_deathRate\"].copy()\n",
    "\n",
    "testing = test_set.drop(\"TARGET_deathRate\",axis=1)\n",
    "testing_labels= test_set[\"TARGET_deathRate\"].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950, 488)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set), len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2438 entries, 0 to 2437\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   avgAnnCount             2438 non-null   float64\n",
      " 1   avgDeathsPerYear        2438 non-null   int64  \n",
      " 2   incidenceRate           2438 non-null   float64\n",
      " 3   medIncome               2438 non-null   int64  \n",
      " 4   popEst2015              2438 non-null   int64  \n",
      " 5   povertyPercent          2438 non-null   float64\n",
      " 6   MedianAgeMale           2438 non-null   float64\n",
      " 7   PercentMarried          2438 non-null   float64\n",
      " 8   PctHS18_24              2438 non-null   float64\n",
      " 9   PctBachDeg18_24         2438 non-null   float64\n",
      " 10  PctHS25_Over            2438 non-null   float64\n",
      " 11  PctBachDeg25_Over       2438 non-null   float64\n",
      " 12  PctEmployed16_Over      2319 non-null   float64\n",
      " 13  PctUnemployed16_Over    2438 non-null   float64\n",
      " 14  PctPrivateCoverage      2438 non-null   float64\n",
      " 15  PctEmpPrivCoverage      2438 non-null   float64\n",
      " 16  PctPublicCoverage       2438 non-null   float64\n",
      " 17  PctPublicCoverageAlone  2438 non-null   float64\n",
      " 18  PctWhite                2438 non-null   float64\n",
      " 19  PctBlack                2438 non-null   float64\n",
      " 20  PctAsian                2438 non-null   float64\n",
      " 21  PctOtherRace            2438 non-null   float64\n",
      " 22  PctMarriedHouseholds    2438 non-null   float64\n",
      " 23  BirthRate               2438 non-null   float64\n",
      " 24  TARGET_deathRate        2438 non-null   float64\n",
      "dtypes: float64(22), int64(3)\n",
      "memory usage: 476.3 KB\n"
     ]
    }
   ],
   "source": [
    "combined.info()\n",
    "# NOTE: PctSomeCol18_24, PctEmployed16_Over,PctPrivateCoverageAlone all contain \n",
    "# less than 2438 non-null values i.e. have null values which require imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems some columns (PctSomeCol18_24, PctEmployed16_Over, PctPrivateCoverageAlone) have null values - \n",
    "# let's validate this\n",
    "# print(combined['PctSomeCol18_24'].isnull().any())\n",
    "# print(combined['PctEmployed16_Over'].isnull().any())\n",
    "# print(combined['PctPrivateCoverageAlone'].isnull().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JJ21KooNRVT"
   },
   "outputs": [],
   "source": [
    "# impute - currently using median!\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer=SimpleImputer(strategy=\"median\")\n",
    "# # fit\n",
    "# imputer.fit(combined)\n",
    "# # array of size 32, with median value of each column\n",
    "# imputer.statistics_ \n",
    "# # transform\n",
    "# x = imputer.transform(combined)\n",
    "# x.shape\n",
    "# # turn np.array back into dataframe\n",
    "# combined = pd.DataFrame(x,columns=combined.columns)\n",
    "# combined.info()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q to self: IS MEDIAN THE BEST CHOICE TO IMPUTE WITH? TRY WITH MODE / MEAN AND SEE WHICH YIELDS BETTER RESULTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate and add features\n",
    "\n",
    "\n",
    "# normalise - make values 0 to 1 - used for neural networks\n",
    "\n",
    "\n",
    "# Standardise - minus mean, divide by variance\n",
    "\n",
    "\n",
    "# no encoding needed e.g. one hot encoding, since all variables are numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scikit learn pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n"
     ]
    }
   ],
   "source": [
    "# could try other imputer types - this one is \"simple\"\n",
    "pipeline = Pipeline([\n",
    "    # ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('imputer',KNNImputer(n_neighbors=2)),\n",
    "    # ('imputer',IterativeImputer(max_iter=10, random_state=0)),\n",
    "    ('std_scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "training_ppln = pipeline.fit_transform(training_set)\n",
    "print(len(training_ppln))\n",
    "# type(combined_ppln), combined.columns\n",
    "# turn it back into a df\n",
    "# training_ppln = pd.DataFrame(data=training_ppln, columns=training.columns)\n",
    "# print(training_ppln.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PIPELINE:*** Imputed since there were missing values in the dataset - used simple imputer with median. StandardScaler to scale the data to be 0 centered with 1 variance - improves model performance (and interpretability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgAnnCount</th>\n",
       "      <th>avgDeathsPerYear</th>\n",
       "      <th>incidenceRate</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>popEst2015</th>\n",
       "      <th>povertyPercent</th>\n",
       "      <th>MedianAgeMale</th>\n",
       "      <th>PercentMarried</th>\n",
       "      <th>PctHS18_24</th>\n",
       "      <th>PctBachDeg18_24</th>\n",
       "      <th>...</th>\n",
       "      <th>PctPrivateCoverage</th>\n",
       "      <th>PctEmpPrivCoverage</th>\n",
       "      <th>PctPublicCoverage</th>\n",
       "      <th>PctPublicCoverageAlone</th>\n",
       "      <th>PctWhite</th>\n",
       "      <th>PctBlack</th>\n",
       "      <th>PctAsian</th>\n",
       "      <th>PctOtherRace</th>\n",
       "      <th>PctMarriedHouseholds</th>\n",
       "      <th>BirthRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.128977</td>\n",
       "      <td>-0.053646</td>\n",
       "      <td>-0.029166</td>\n",
       "      <td>0.799382</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>-0.981118</td>\n",
       "      <td>-0.187978</td>\n",
       "      <td>0.286607</td>\n",
       "      <td>-0.151943</td>\n",
       "      <td>0.297289</td>\n",
       "      <td>...</td>\n",
       "      <td>1.221080</td>\n",
       "      <td>1.557573</td>\n",
       "      <td>-0.784939</td>\n",
       "      <td>-0.829350</td>\n",
       "      <td>0.662262</td>\n",
       "      <td>-0.567052</td>\n",
       "      <td>-0.213109</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.529158</td>\n",
       "      <td>-0.458523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.394742</td>\n",
       "      <td>-0.318743</td>\n",
       "      <td>-0.249612</td>\n",
       "      <td>-0.911029</td>\n",
       "      <td>-0.296052</td>\n",
       "      <td>0.598820</td>\n",
       "      <td>0.447303</td>\n",
       "      <td>-1.045092</td>\n",
       "      <td>2.270699</td>\n",
       "      <td>-0.636871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776117</td>\n",
       "      <td>-0.525352</td>\n",
       "      <td>0.385399</td>\n",
       "      <td>0.584977</td>\n",
       "      <td>-0.990731</td>\n",
       "      <td>1.517064</td>\n",
       "      <td>-0.417955</td>\n",
       "      <td>-0.506876</td>\n",
       "      <td>-0.761643</td>\n",
       "      <td>-1.375816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142265</td>\n",
       "      <td>-0.073528</td>\n",
       "      <td>0.447527</td>\n",
       "      <td>-0.236550</td>\n",
       "      <td>-0.049226</td>\n",
       "      <td>-0.371043</td>\n",
       "      <td>-1.169776</td>\n",
       "      <td>0.558675</td>\n",
       "      <td>-0.735580</td>\n",
       "      <td>-1.081709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060804</td>\n",
       "      <td>-0.119448</td>\n",
       "      <td>-0.679740</td>\n",
       "      <td>-0.458931</td>\n",
       "      <td>0.566108</td>\n",
       "      <td>-0.588897</td>\n",
       "      <td>0.129873</td>\n",
       "      <td>0.054313</td>\n",
       "      <td>0.627064</td>\n",
       "      <td>1.457320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.436952</td>\n",
       "      <td>-0.365135</td>\n",
       "      <td>-1.178503</td>\n",
       "      <td>-0.860638</td>\n",
       "      <td>-0.320677</td>\n",
       "      <td>0.880393</td>\n",
       "      <td>-1.554795</td>\n",
       "      <td>-0.486638</td>\n",
       "      <td>-1.638565</td>\n",
       "      <td>-1.370854</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.517933</td>\n",
       "      <td>-1.112843</td>\n",
       "      <td>0.214451</td>\n",
       "      <td>0.231395</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>-0.537742</td>\n",
       "      <td>-0.473139</td>\n",
       "      <td>0.327809</td>\n",
       "      <td>0.636916</td>\n",
       "      <td>5.825411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.317358</td>\n",
       "      <td>-0.203868</td>\n",
       "      <td>-0.153520</td>\n",
       "      <td>-0.741064</td>\n",
       "      <td>-0.233932</td>\n",
       "      <td>0.332890</td>\n",
       "      <td>0.216292</td>\n",
       "      <td>0.272288</td>\n",
       "      <td>0.365621</td>\n",
       "      <td>-0.347727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604929</td>\n",
       "      <td>-0.632168</td>\n",
       "      <td>0.714146</td>\n",
       "      <td>0.366093</td>\n",
       "      <td>0.824078</td>\n",
       "      <td>-0.521763</td>\n",
       "      <td>-0.459222</td>\n",
       "      <td>-0.539978</td>\n",
       "      <td>-0.160197</td>\n",
       "      <td>0.806795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avgAnnCount  avgDeathsPerYear  incidenceRate  medIncome  popEst2015  \\\n",
       "0    -0.128977         -0.053646      -0.029166   0.799382   -0.041545   \n",
       "1    -0.394742         -0.318743      -0.249612  -0.911029   -0.296052   \n",
       "2    -0.142265         -0.073528       0.447527  -0.236550   -0.049226   \n",
       "3    -0.436952         -0.365135      -1.178503  -0.860638   -0.320677   \n",
       "4    -0.317358         -0.203868      -0.153520  -0.741064   -0.233932   \n",
       "\n",
       "   povertyPercent  MedianAgeMale  PercentMarried  PctHS18_24  PctBachDeg18_24  \\\n",
       "0       -0.981118      -0.187978        0.286607   -0.151943         0.297289   \n",
       "1        0.598820       0.447303       -1.045092    2.270699        -0.636871   \n",
       "2       -0.371043      -1.169776        0.558675   -0.735580        -1.081709   \n",
       "3        0.880393      -1.554795       -0.486638   -1.638565        -1.370854   \n",
       "4        0.332890       0.216292        0.272288    0.365621        -0.347727   \n",
       "\n",
       "   ...  PctPrivateCoverage  PctEmpPrivCoverage  PctPublicCoverage  \\\n",
       "0  ...            1.221080            1.557573          -0.784939   \n",
       "1  ...           -0.776117           -0.525352           0.385399   \n",
       "2  ...            0.060804           -0.119448          -0.679740   \n",
       "3  ...           -1.517933           -1.112843           0.214451   \n",
       "4  ...           -0.604929           -0.632168           0.714146   \n",
       "\n",
       "   PctPublicCoverageAlone  PctWhite  PctBlack  PctAsian  PctOtherRace  \\\n",
       "0               -0.829350  0.662262 -0.567052 -0.213109      0.003537   \n",
       "1                0.584977 -0.990731  1.517064 -0.417955     -0.506876   \n",
       "2               -0.458931  0.566108 -0.588897  0.129873      0.054313   \n",
       "3                0.231395  0.672040 -0.537742 -0.473139      0.327809   \n",
       "4                0.366093  0.824078 -0.521763 -0.459222     -0.539978   \n",
       "\n",
       "   PctMarriedHouseholds  BirthRate  \n",
       "0              0.529158  -0.458523  \n",
       "1             -0.761643  -1.375816  \n",
       "2              0.627064   1.457320  \n",
       "3              0.636916   5.825411  \n",
       "4             -0.160197   0.806795  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ppln_df = pd.DataFrame(data=training_ppln, columns=training_set.columns)\n",
    "training_ppln_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiM5kym6NRww"
   },
   "source": [
    "# **Exercise 3**\n",
    "\n",
    "Fit linear regression models to the pre-processed data using: Ordinary least squares (OLS), Lasso and Ridge models. Choose suitable regularisation weights for Lasso and Ridge regression and include a description in text of how they were chosen. In your submitted solution make sure you set the values for the regularisation weights equal to those you identify from your experiment(s). Quantitatively compare your results from all three models and report the best performing one. Include code for all steps above. (10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use combined df\n",
    "# split train test sets 80:20 - use stratified sampling based on a feature/variable?\n",
    "# do linear regression on training set with cross validation \n",
    "# get metrics from cross validation and aggregate results (E.g. avg)\n",
    "# to measure how effective selected hyperparameters are\n",
    "# use gridsearchCV to automatically find the best hyper parameters for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data=testing\n",
    "some_labels=testing_labels\n",
    "some_data_prepared=pipeline.transform(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bv9wFbldPo45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#OLS - Ordinary Least Squares\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(training_ppln, training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 349.7674353126292, 'rmse': 18.702070348296445, 'mae': 13.770841594352044, 'r2': 0.574984360978217}\n"
     ]
    }
   ],
   "source": [
    "predicted = lin_reg.predict(some_data_prepared)\n",
    "ols_metrics = {}\n",
    "# print(\"Predictions:\", predicted)\n",
    "# print(\"Labels:\", list(some_labels))\n",
    "ols_metrics['mse'] = mean_squared_error(list(some_labels), predicted)\n",
    "ols_metrics['rmse'] = np.sqrt(ols_metrics['mse'])\n",
    "ols_metrics['mae'] = mean_absolute_error(list(some_labels), predicted)\n",
    "ols_metrics['r2'] = r2_score(list(some_labels), predicted)\n",
    "\n",
    "print(ols_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best_alphas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03489999999999997"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso = Lasso()\n",
    "\n",
    "#regularisation strength - alpha\n",
    "param_grid = {'alpha': np.arange(0.03,0.05,0.0001)}\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object - using 5 folds, could try 10 folds too or more\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the data using the grid search object\n",
    "grid_search.fit(training_ppln, training_labels)\n",
    "\n",
    "# Get the best regularization weight\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "lasso_best_alphas.append(best_alpha)\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03489999999999997]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_best_alphas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BEST LASSO REGULARISATION WEIGHT:***\n",
    "The best value of alpha found for Lasso was 0.0415. I found this value for alpha by starting with a relatively large range of values for alpha (0.01 to 10, incrementing with 0.01) and iteratively narrowing down the range (and size of increments) to converge on a more optimal (and granular) value for alpha.\n",
    "The best values found for alpha after each iteration were \\[0.01, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04,0.042, 0.041, 0.0415\\]\n",
    "However, I decided to try it for a second time.\n",
    "\n",
    "**SECOND TIME ROUND:**\n",
    "The best values found for alpha after each iteration were \\[0.03, 0.032, 0.0315, 0.0315\\]\n",
    "\n",
    "**DECIDER:**\n",
    "To decide on which value to use (between 0.0315 and 0.0415), I tested the range from 0.03 to 0.05, incrementing by 0.0001. The best value for alpha was shown to be 0.0315\n",
    "\n",
    "\n",
    "So, the value I decided to use was 0.0315 for alpha.\n",
    "\n",
    "**Testing:**\n",
    "When testing the model below, I still tested 0.0415 against 0.0315, even though 0.0315 was evaluated to be the best value for alpha on multiple occasions (even when tested against 0.0415), when using GridSearchCV. Using the test blocks below, 0.0415 actually performed better than 0.0315, however, I decided to stick with 0.0315 since the metrics calculated by GridSearchCV are an average of 10 cross validation folds, where as my test set was only obtained by shuffle splitting on 20% of the data. Hence, when my model has to deal with new unseen data, I trust the results from CV to give me a better indicator of which value of alpha is better, compared to the results obtained from simply testing with my test data from an 80:20 test split.\n",
    "\n",
    "Essentially, since CV tests using multiple train/test splits, as opposed to using 1 test split, the result from CV is more reliable and uses an averaged result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0315\n",
    "lasso = Lasso(alpha=a).fit(training_ppln, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0315 : {'mse': 350.2554704233628, 'rmse': 18.71511342266893, 'mae': 13.796230203265317, 'r2': 0.5743913310574409}\n"
     ]
    }
   ],
   "source": [
    "predicted = lasso.predict(some_data_prepared)\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "metrics['mse'] = mean_squared_error(list(some_labels), predicted)\n",
    "metrics['rmse'] = np.sqrt(metrics['mse'])\n",
    "metrics['mae'] = mean_absolute_error(list(some_labels), predicted)\n",
    "metrics['r2'] = r2_score(list(some_labels), predicted)\n",
    "\n",
    "lasso_scores[a] = metrics\n",
    "\n",
    "print(f\"{a} : {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0315: {'mse': 350.2554704233628,\n",
       "  'rmse': 18.71511342266893,\n",
       "  'mae': 13.796230203265317,\n",
       "  'r2': 0.5743913310574409}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_scores\n",
    "# a big difference between MAE and RMSE could suggest outliersa are affecting the scoring since MSE/RMSE are not robust to outliers (MAE is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best_alphas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [117], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(ridge, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Fit the model to the data using the grid search object\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(training_ppln, training_labels)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Get the best regularization weight\u001b[39;00m\n\u001b[0;32m     14\u001b[0m best_alpha \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_[\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1130\u001b[0m, in \u001b[0;36mRidge.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1121\u001b[0m _accept_sparse \u001b[39m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[39m.\u001b[39missparse(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver)\n\u001b[0;32m   1122\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m   1123\u001b[0m     X,\n\u001b[0;32m   1124\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     y_numeric\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   1129\u001b[0m )\n\u001b[1;32m-> 1130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:889\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m         \u001b[39m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[0;32m    887\u001b[0m         params \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _ridge_regression(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha,\n\u001b[0;32m    893\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    894\u001b[0m         max_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter,\n\u001b[0;32m    895\u001b[0m         tol\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol,\n\u001b[0;32m    896\u001b[0m         solver\u001b[39m=\u001b[39msolver,\n\u001b[0;32m    897\u001b[0m         positive\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive,\n\u001b[0;32m    898\u001b[0m         random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state,\n\u001b[0;32m    899\u001b[0m         return_n_iter\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    900\u001b[0m         return_intercept\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    901\u001b[0m         check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    902\u001b[0m         fit_intercept\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept,\n\u001b[0;32m    903\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    904\u001b[0m     )\n\u001b[0;32m    905\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[0;32m    907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:699\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[1;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, positive, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input, fit_intercept)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 699\u001b[0m         coef \u001b[39m=\u001b[39m _solve_cholesky(X, y, alpha)\n\u001b[0;32m    700\u001b[0m     \u001b[39mexcept\u001b[39;00m linalg\u001b[39m.\u001b[39mLinAlgError:\n\u001b[0;32m    701\u001b[0m         \u001b[39m# use SVD solver if matrix is singular\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         solver \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msvd\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:205\u001b[0m, in \u001b[0;36m_solve_cholesky\u001b[1;34m(X, y, alpha)\u001b[0m\n\u001b[0;32m    202\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    203\u001b[0m n_targets \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 205\u001b[0m A \u001b[39m=\u001b[39m safe_sparse_dot(X\u001b[39m.\u001b[39;49mT, X, dense_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    206\u001b[0m Xy \u001b[39m=\u001b[39m safe_sparse_dot(X\u001b[39m.\u001b[39mT, y, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m one_alpha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray_equal(alpha, \u001b[39mlen\u001b[39m(alpha) \u001b[39m*\u001b[39m [alpha[\u001b[39m0\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py:155\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m--> 155\u001b[0m     sparse\u001b[39m.\u001b[39;49missparse(a)\n\u001b[0;32m    156\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    157\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    158\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    159\u001b[0m ):\n\u001b[0;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m    161\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:1301\u001b[0m, in \u001b[0;36misspmatrix\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m             \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m-> 1301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39misspmatrix\u001b[39m(x):\n\u001b[0;32m   1302\u001b[0m     \u001b[39m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \n\u001b[0;32m   1304\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "#regularisation strength - alpha\n",
    "param_grid = {'alpha': np.arange(0.001, 20, 0.001)}\n",
    "\n",
    "\n",
    "# Create a GridSearchCV object - using 5 folds, could try 10 folds too or more\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model to the data using the grid search object\n",
    "grid_search.fit(training_ppln, training_labels)\n",
    "\n",
    "# Get the best regularization weight\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "ridge_best_alphas.append(best_alpha)\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_best_alphas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BEST RIDGE REGULARISATION WEIGHT:***\n",
    "The best value of alpha found for Lasso was 13.35. I found this value for alpha by starting with a relatively large range of values for alpha (0.01 to 100, increment of 0.01) and iteratively narrowing down the range to  converge on a more optimal value for alpha.\n",
    "The best values found for alpha after each iteration were \\[10, 10, 15, 12.5, 13.75, 13, 13.5, 13.25, 13.4, 13.35, 13.35, 13.35\\]\n",
    "\n",
    "**SECOND TRY:**\n",
    "The best values found for alpha after each iteration were \\[ 13.35, 13, 13.4, 13.35, 13.352\\]\n",
    "\n",
    "***OVERALL:*** Both tests seemed to agree on ~13.35 being the best regularisation weight, hence I used *13.352*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_a = 13.352\n",
    "ridge = Ridge(alpha=ridge_a).fit(training_ppln, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.352 : {'mse': 350.0033933788863, 'rmse': 18.70837762551543, 'mae': 13.7823445447555, 'r2': 0.57469763940786}\n"
     ]
    }
   ],
   "source": [
    "predicted = ridge.predict(some_data_prepared)\n",
    "\n",
    "ridge_metrics = {}\n",
    "\n",
    "ridge_metrics['mse'] = mean_squared_error(list(some_labels), predicted)\n",
    "ridge_metrics['rmse'] = np.sqrt(ridge_metrics['mse'])\n",
    "ridge_metrics['mae'] = mean_absolute_error(list(some_labels), predicted)\n",
    "ridge_metrics['r2'] = r2_score(list(some_labels), predicted)\n",
    "\n",
    "ridge_scores[ridge_a] = ridge_metrics\n",
    "\n",
    "print(f\"{ridge_a} : {ridge_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13.352: {'mse': 350.0033933788863,\n",
       "  'rmse': 18.70837762551543,\n",
       "  'mae': 13.7823445447555,\n",
       "  'r2': 0.57469763940786}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: \n",
      "{'mse': 349.7674353126292, 'rmse': 18.702070348296445, 'mae': 13.770841594352044, 'r2': 0.574984360978217} \n",
      "Lasso: \n",
      "{0.0315: {'mse': 350.2554704233628, 'rmse': 18.71511342266893, 'mae': 13.796230203265317, 'r2': 0.5743913310574409}} \n",
      "Ridge: \n",
      "{13.352: {'mse': 350.0033933788863, 'rmse': 18.70837762551543, 'mae': 13.7823445447555, 'r2': 0.57469763940786}}\n"
     ]
    }
   ],
   "source": [
    "# compare the scores to choose best model\n",
    "print(f\"OLS: \\n{ols_metrics} \\nLasso: \\n{lasso_scores} \\nRidge: \\n{ridge_scores}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BEST PERFORMING LINEAR REGRESSOR:*** The Lasso model seems to perform the best in every metric (MSE, RMSE, MAE and r2 score). It has the lowest error values and highest r2 score, suggesting it is the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdx4FmjqPpVJ"
   },
   "source": [
    "# **Exercise 4**\n",
    "\n",
    "Use Lasso regression and the best regularisation weight identified from Exercise 3 to identify the five most important/relevant features for the provided data set and regression task. Report what these are desceding order of their importance. (5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vC63VPnQXI_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('incidenceRate', {'weight': 10.109157052142852, 'abs_weight': 10.109157052142852}), ('avgDeathsPerYear', {'weight': 7.593911856279176, 'abs_weight': 7.593911856279176}), ('PctBachDeg25_Over', {'weight': -7.451254370308918, 'abs_weight': 7.451254370308918}), ('PctMarriedHouseholds', {'weight': -6.969583339052497, 'abs_weight': 6.969583339052497}), ('PercentMarried', {'weight': 6.517156003327249, 'abs_weight': 6.517156003327249})] \n",
      "\n",
      "1. incidenceRate\n",
      "2. avgDeathsPerYear\n",
      "3. PctBachDeg25_Over\n",
      "4. PctMarriedHouseholds\n",
      "5. PercentMarried\n"
     ]
    }
   ],
   "source": [
    "feature_weights = {}\n",
    "feature_names = training_ppln_df.columns.values\n",
    "weights = lasso.coef_\n",
    "count = 0\n",
    "\n",
    "for weight in weights:\n",
    "    feature_weights[feature_names[count]] = {'weight':weight, 'abs_weight':np.abs(weight)}\n",
    "    count +=1\n",
    "\n",
    "sorted_feature_weights = sorted(feature_weights.items(), key=lambda x: x[1]['abs_weight'], reverse=True)\n",
    "\n",
    "# top 5 features and their weights\n",
    "print(sorted_feature_weights[:5],'\\n')\n",
    "\n",
    "count = 1\n",
    "lasso_top_features = []\n",
    "# print features\n",
    "for fw in sorted_feature_weights[:5]:\n",
    "    print(str(count)+\".\",fw[0])\n",
    "    lasso_top_features.append(fw[0])\n",
    "    count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 most heavily weighted lasso features are printed in the cell above - they are ordered by absolute values of their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. incidenceRate, weight: 10.109157052142852\n",
      "2. avgDeathsPerYear, weight: 7.593911856279176\n",
      "3. PctBachDeg25_Over, weight: -7.451254370308918\n",
      "4. PctMarriedHouseholds, weight: -6.969583339052497\n",
      "5. PercentMarried, weight: 6.517156003327249\n",
      "6. PctPrivateCoverage, weight: -4.917033047331178\n",
      "7. avgAnnCount, weight: -4.679856119017145\n",
      "8. popEst2015, weight: -3.5789110573788285\n",
      "9. PctOtherRace, weight: -3.39175111779589\n",
      "10. MedianAgeMale, weight: -3.225909863471011\n",
      "11. PctEmployed16_Over, weight: -3.1504220631383504\n",
      "12. PctEmpPrivCoverage, weight: 2.783535206742418\n",
      "13. PctPublicCoverageAlone, weight: 2.7278101236478762\n",
      "14. PctWhite, weight: -2.330883840664614\n",
      "15. PctHS18_24, weight: 2.1653153911297767\n",
      "16. PctPublicCoverage, weight: -2.15511648198377\n",
      "17. BirthRate, weight: -2.1081950200966904\n",
      "18. PctHS25_Over, weight: 2.0019565286253984\n",
      "19. PctBlack, weight: -1.9296961403229462\n",
      "20. povertyPercent, weight: 0.792654498405568\n",
      "21. PctAsian, weight: 0.32616682464109203\n",
      "22. medIncome, weight: 0.2406442630284504\n",
      "23. PctBachDeg18_24, weight: 0.20555202163708833\n",
      "24. PctUnemployed16_Over, weight: 0.09628490377427955\n"
     ]
    }
   ],
   "source": [
    "# print all lasso features and wights - help with feature selection\n",
    "count = 1\n",
    "for fw in sorted_feature_weights:\n",
    "    print(f\"{str(count)}. {fw[0]}, weight: {fw[1]['weight']}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQvZqdqGQ_pH"
   },
   "source": [
    "# **Exercise 5**\n",
    "\n",
    "Fit a Random Forest regression model to the training data and quantitatively evaluate and compare the Random Forest regression model with the best linear regression model identified from Exercise 3. Report which model provides the best results. Next, report the top five most important/relevant features for the provided data set and regression task identified using the Random Forest model. Comment on how these compare with the features identified from Lasso regression? (14 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbFXu6UiQ-gv"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(random_state=21)\n",
    "parameters = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "  \"max_features\" : [None, 1, 5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search  = GridSearchCV(forest, parameters, scoring='neg_mean_squared_error', cv=10)\n",
    "# grid_search.fit(training_ppln, np.ravel(training_labels))\n",
    "# forest_predictions = grid_search.predict(some_data_prepared)\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score_mse = grid_search.best_score_\n",
    "# print(f\"best_params: {best_params} \\nbest_score: {best_score_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd gridsearch test - takes too long to run, over 1000 minutes!\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# forest = RandomForestRegressor(random_state=21)\n",
    "# parameters = {\n",
    "#   'n_estimators': [50, 100, 200, 300, 500, 700, 900, 1000],\n",
    "#   'max_depth': [None, 5, 8, 10, 15, 20, 25, 30, 35, 40],\n",
    "#   \"max_features\" : [None, 1, 5, 8, 10, 15, 20, 30]\n",
    "# }\n",
    "\n",
    "# grid_search  = GridSearchCV(forest, parameters, scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd gridsearch test\n",
    "forest = RandomForestRegressor(random_state=21)\n",
    "parameters = {\n",
    "  'n_estimators': [10, 50, 100, 200, 300],\n",
    "  'max_depth': [None, 5, 10, 15, 20, 30],\n",
    "  \"max_features\" : [None, 1, 5, 10, 1, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search  = GridSearchCV(forest, parameters, scoring='neg_mean_squared_error', cv=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(training_ppln, training_labels)\n\u001b[0;32m      2\u001b[0m \u001b[39m# forest_predictions = grid_search.predict(some_data_prepared)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Hamzah\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(training_ppln, training_labels)\n",
    "# forest_predictions = grid_search.predict(some_data_prepared)\n",
    "best_params = grid_search.best_params_\n",
    "best_score_nmse = grid_search.best_score_\n",
    "print(f\"best_params: {best_params} \\nbest_score: {best_score_nmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1st test:*** best_params: {'max_depth': 30, 'max_features': 20, 'n_estimators': 100} \n",
    "best_score: -353.79785219521494\n",
    "\n",
    "***2nd test***: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = {}\n",
    "forest_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=30, max_features=20, random_state=21)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=30, max_features=20, random_state=21)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=30, max_features=20, random_state=21)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_params = {'n_estimators': 100,\n",
    "                'max_depth': 30,\n",
    "                \"max_features\" : 20}\n",
    "\n",
    "forest_scores[forest_count] = [forest_params]\n",
    "\n",
    "forest = RandomForestRegressor(random_state=21, n_estimators = forest_params['n_estimators'], max_depth = forest_params['max_depth'], max_features = forest_params['max_features'])\n",
    "forest.fit(training_ppln, training_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 377.8729256633464, 'rmse': 19.438953821215442, 'mae': 13.803043889716838, 'r2': 0.57469763940786}\n"
     ]
    }
   ],
   "source": [
    "# metrics RMSE, MSE, MAE, R2\n",
    "# predicted = forest.predict(some_data_prepared)\n",
    "forest_predictions = forest.predict(some_data_prepared)\n",
    "forest_metrics = {}\n",
    "# print(\"Predictions:\", predicted)\n",
    "# print(\"Labels:\", list(some_labels))\n",
    "forest_metrics['mse'] = mean_squared_error(list(some_labels), forest_predictions)\n",
    "forest_metrics['rmse'] = np.sqrt(forest_metrics['mse'])\n",
    "forest_metrics['mae'] = mean_absolute_error(list(some_labels), forest_predictions)\n",
    "forest_metrics['r2'] = r2_score(list(some_labels), predicted)\n",
    "\n",
    "print(forest_metrics)\n",
    "forest_scores[forest_count].append(forest_metrics)\n",
    "\n",
    "forest_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('incidenceRate', {'weight': 0.19629003012808988, 'abs_weight': 0.19629003012808988}), ('PctBachDeg25_Over', {'weight': 0.19076639605694626, 'abs_weight': 0.19076639605694626}), ('medIncome', {'weight': 0.060755723454791306, 'abs_weight': 0.060755723454791306}), ('PctHS25_Over', {'weight': 0.050703114693208054, 'abs_weight': 0.050703114693208054}), ('avgDeathsPerYear', {'weight': 0.04128921115295002, 'abs_weight': 0.04128921115295002})] \n",
      "\n",
      "1. incidenceRate\n",
      "2. PctBachDeg25_Over\n",
      "3. medIncome\n",
      "4. PctHS25_Over\n",
      "5. avgDeathsPerYear\n",
      "6. PctPublicCoverageAlone\n",
      "7. PctOtherRace\n",
      "8. PctEmployed16_Over\n",
      "9. povertyPercent\n",
      "10. PctHS18_24\n",
      "11. PctUnemployed16_Over\n",
      "12. PctMarriedHouseholds\n",
      "13. PctBlack\n",
      "14. PctPrivateCoverage\n",
      "15. avgAnnCount\n",
      "16. popEst2015\n",
      "17. PctAsian\n",
      "18. PercentMarried\n",
      "19. BirthRate\n",
      "20. PctWhite\n",
      "21. MedianAgeMale\n",
      "22. PctBachDeg18_24\n",
      "23. PctEmpPrivCoverage\n",
      "24. PctPublicCoverage\n"
     ]
    }
   ],
   "source": [
    "# show top 5 features from RF\n",
    "feature_weights = {}\n",
    "feature_names = training_ppln_df.columns.values\n",
    "weights = forest.feature_importances_\n",
    "count = 0\n",
    "\n",
    "for weight in weights:\n",
    "    feature_weights[feature_names[count]] = {'weight':weight, 'abs_weight':np.abs(weight)}\n",
    "    count +=1\n",
    "\n",
    "sorted_feature_weights = sorted(feature_weights.items(), key=lambda x: x[1]['abs_weight'], reverse=True)\n",
    "\n",
    "# top 5 features and their weights\n",
    "print(sorted_feature_weights[:5],'\\n')\n",
    "\n",
    "count = 1\n",
    "forest_top_features = []\n",
    "# print features\n",
    "for fw in sorted_feature_weights:\n",
    "    print(str(count)+\".\",fw[0])\n",
    "    if count <6:\n",
    "        forest_top_features.append(fw[0])\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['incidenceRate',\n",
       " 'PctBachDeg25_Over',\n",
       " 'medIncome',\n",
       " 'PctHS25_Over',\n",
       " 'avgDeathsPerYear']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_top_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest vs Linear Regressors:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- OLS Metrics ---- \n",
      "{'mse': 349.7674353126292, 'rmse': 18.702070348296445, 'mae': 13.770841594352044, 'r2': 0.574984360978217}\n",
      "\n",
      "---- Lasso Metrics ---- \n",
      "{'mse': 350.2554704233628, 'rmse': 18.71511342266893, 'mae': 13.796230203265317, 'r2': 0.5743913310574409}\n",
      "\n",
      "---- Ridge Metrics ---- \n",
      "{'mse': 350.0033933788863, 'rmse': 18.70837762551543, 'mae': 13.7823445447555, 'r2': 0.57469763940786}\n",
      "\n",
      "---- RF Metrics ---- \n",
      "{'mse': 377.8729256633464, 'rmse': 19.438953821215442, 'mae': 13.803043889716838, 'r2': 0.57469763940786}\n",
      "\n",
      "---- Model with the best metrics ---- \n",
      " OLS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare metrics with best linear model metrics - pick which yields better results\n",
    "print(f\"---- OLS Metrics ---- \\n{ols_metrics}\\n\")\n",
    "print(f\"---- Lasso Metrics ---- \\n{metrics}\\n\")\n",
    "print(f\"---- Ridge Metrics ---- \\n{ridge_metrics}\\n\")\n",
    "print(f\"---- RF Metrics ---- \\n{forest_metrics}\\n\")\n",
    "\n",
    "# report which model provides the best results\n",
    "print(f\"---- Model with the best metrics ---- \\n OLS \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 5 Features for Random Forest:**\n",
    "\n",
    "\n",
    "Lasso features printed for ease of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- RF Top 5 Features ---- \n",
      "['incidenceRate', 'PctBachDeg25_Over', 'medIncome', 'PctHS25_Over', 'avgDeathsPerYear']\n",
      "\n",
      "---- Lasso Top 5 Features ---- \n",
      "['incidenceRate', 'avgDeathsPerYear', 'PctBachDeg25_Over', 'PctMarriedHouseholds', 'PercentMarried']\n"
     ]
    }
   ],
   "source": [
    "# top 5 features from random forest regressor\n",
    "print(f\"---- RF Top 5 Features ---- \\n{forest_top_features}\\n\")\n",
    "\n",
    "# compare with the list of features from lasso\n",
    "print(f\"---- Lasso Top 5 Features ---- \\n{lasso_top_features}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest interesection and difference of features, with Lasso:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Intersection of Features with Lasso ---- \n",
      "['incidenceRate', 'PctBachDeg25_Over', 'avgDeathsPerYear']\n",
      "\n",
      "---- Features exclusive to RF ---- \n",
      "['medIncome', 'PctHS25_Over']\n",
      "\n",
      "---- Features exclusive to LR ---- \n",
      "['PctMarriedHouseholds', 'PercentMarried']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate intersection and differences with best linear regressor\n",
    "linear_regressor_features = lasso_top_features\n",
    "\n",
    "feature_intersection = []\n",
    "rffeature_difference = []\n",
    "lrfeature_difference = []\n",
    "\n",
    "for rffeature in forest_top_features:\n",
    "    if rffeature in linear_regressor_features:\n",
    "        feature_intersection.append(rffeature)\n",
    "    else:\n",
    "        rffeature_difference.append(rffeature)\n",
    "\n",
    "# get the rest of the unique features by comparing the other way\n",
    "for lrfeature in linear_regressor_features:\n",
    "    if not (lrfeature in forest_top_features):\n",
    "        lrfeature_difference.append(lrfeature)\n",
    "\n",
    "print(f\"---- Intersection of Features with Lasso ---- \\n{feature_intersection}\\n\")\n",
    "\n",
    "print(f\"---- Features exclusive to RF ---- \\n{rffeature_difference}\\n\")\n",
    "\n",
    "print(f\"---- Features exclusive to LR ---- \\n{lrfeature_difference}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Lasso, the Random Forest Regressor highly prioritises the incidence rate of a county in predicting death rate. This could make sense since the more people there are diagnosed with cancer, the higher you could expect the death rate to be, in that county.\n",
    "Another feature which overlaps with Lasso, is the PctBachDeg25_Over. Intuitively, it isn't as clear to explain why this feature would be so weighty in predicting death rates, although still possible (e.g. a hgiher percentage of people with bachelor degrees could suggest more wealth in an area and hence better healthcare), however it makes sense when thinking back to the correlation matrix, where this feature was shown to be the most correlated feature with the death rate in the entire dataset.\n",
    "\n",
    "\n",
    "However, the random forest regressor differs to lasso by taking a high weighting for median income, PctHS25_Over and PctPublicCoverageAlone.\n",
    "On the other hand, lasso prioritises PctPrivateCoverage, PercentMarried and avgDeathsPerYear.\n",
    "\n",
    "\n",
    "The features prioritised by Random Forest seem to make sense. Median income can affect the level of healthcare afforded, directly affecting death rates. Similarly, PctPublicCoverageAlone would directly affect the death rate, since it represents the level of healthcare in an area. PctHS25_Over wouldn't be assumed to be as directly related, similarly to PctBachDeg25_Over. But for the same reasons stated with PctBachDeg25_Over, the level of education achieved by people in an area could also affect wealth and hence the quality of healthcare they can afford, hence having an impact on the predicted death rate in that county.\n",
    "\n",
    "The PctPrivateCoverage and avgDeathsPerYear features prioritised by lasso make intuitive sense, since you would expect these variables to directly influence the predicted death rate. However, you wouldn't expect the percenatge of married people to play a large part. Whilst it wouldn't be expected to directly affect predictions, being married could give people access to better healthcare since they could have financial support and assistance from their partners, affecting survival rates (and therefore death rate).\n",
    "\n",
    "\n",
    "Overall, I would say the models are similar, with regards to which features they prioritise. While it seems like they differ more than they align, the type of information that can be extracted from these features seems to remain quite consistent between the 2 models. They both suggest that the incidence rate and level of education heavvily affect predictions. However, where they differ, they still suggest that the level/quality of healthcare, education and hence, wealth of individuals in a county, play a vital role in predicting the death rate for that county."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DISCLAIMER:*** Since writing the above cell, the features have changed since I altered the cleaning process to include feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jg-Tksx5QXiL"
   },
   "source": [
    "# **Exercise 6**\n",
    "\n",
    "Use the provided test example data ('Test_data_example.csv' and 'Test_data_example_targets.csv') to write an inference script to evaluate the best regression model identified from preceding exercises. First re-train the chosen regression model using all of the provided training data and test your predictions on the provided example test data. Note - the final evaluation of your submission will be done by replacing this example test data with held out (unseen) test data that is not provided to you. But the format of this \"unseen\" test data will be identical to the example test data provided to you. Use the code snippet provided below to prepare your inference script to predict targets for the unseen test data. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcmuUJMODD2Q"
   },
   "outputs": [],
   "source": [
    "## Read in the provided example test data\n",
    "test_data_path = 'Test_data_example.csv'\n",
    "test_targets_path ='Test_data_example_targets.csv'\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_targets = pd.read_csv(test_targets_path)\n",
    "## Retrain your chosen regression model here \n",
    "# For example: lin_reg = LinearRegression()\n",
    "# lin_reg.fit(X_train,y_train) where X_train and y_train is provided training data\n",
    "# Next write the lines of code required to predict on unseen test data and evaluate your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen model: LinearRegression()\n",
      "mse: 513.2335550816714\n",
      "rmse: 22.6546585734959\n",
      "mae: 16.555783616302364\n",
      "r2: 0.32162775728435244\n"
     ]
    }
   ],
   "source": [
    "training_final=combined_ppln.drop(\"TARGET_deathRate\",axis=1)\n",
    "training_labels_final=combined_ppln[\"TARGET_deathRate\"].copy()\n",
    "training_final_ppln = pipeline.fit_transform(training_final)\n",
    "\n",
    "test_combined = pd.merge(test_data, test_targets, left_index=True, right_index=True)\n",
    "# remove implausible values\n",
    "test_combined_ppln = initial_pipeline.fit_transform(test_combined)\n",
    "# split targets from features\n",
    "testing_final = test_combined_ppln.drop(\"TARGET_deathRate\",axis=1)\n",
    "testing_labels_final = test_combined_ppln[\"TARGET_deathRate\"].copy()\n",
    "# impute and scale\n",
    "testing_final_ppln = pipeline.fit_transform(testing_final)\n",
    "\n",
    "ols = lin_reg\n",
    "# chosen model\n",
    "chosen_model = ols\n",
    "chosen_model.fit(training_final_ppln, training_labels_final)\n",
    "final_predictions = chosen_model.predict(testing_final_ppln)\n",
    "\n",
    "print(f\"chosen model: {chosen_model}\")\n",
    "metrics\n",
    "mse = mean_squared_error((testing_labels_final.values), final_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error((testing_labels_final), final_predictions)\n",
    "r2 = r2_score((testing_labels_final), final_predictions)\n",
    "\n",
    "print(f\"mse: {mse}\")\n",
    "print(f\"rmse: {rmse}\")\n",
    "print(f\"mae: {mae}\")\n",
    "print(f\"r2: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5611M-Coursework Assessment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e85b9385b78cc0f4bde3ac16ced38f32c4bb331e413e9d9541fc5ff5fa933235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
